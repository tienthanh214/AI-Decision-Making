{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f172b7e6",
   "metadata": {},
   "source": [
    "# Traveler's Dilemma\n",
    "Simple Game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369a5d11",
   "metadata": {},
   "source": [
    "*Ghi chú:* **Các giải thuật dưới đây là những lời giải tốt nhất tìm được để chứng minh cho kết luận của bài toán. Các giải thuật khác đã thử nghiệm và kết quả của chúng được ghi trong báo cáo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd87c8",
   "metadata": {},
   "source": [
    "## Resource\n",
    "Add the necessary packages and declare some useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fad34be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Pkg.installed() is deprecated\n",
      "└ @ Pkg C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\Pkg.jl:595\n",
      "┌ Warning: Pkg.installed() is deprecated\n",
      "└ @ Pkg C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\Pkg.jl:595\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `C:\\Users\\Admin\\.julia\\registries\\General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Admin\\.julia\\environments\\v1.7\\Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\Admin\\.julia\\environments\\v1.7\\Manifest.toml`\n",
      "┌ Warning: Pkg.installed() is deprecated\n",
      "└ @ Pkg C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\Pkg.jl:595\n",
      "┌ Warning: Pkg.installed() is deprecated\n",
      "└ @ Pkg C:\\buildbot\\worker\\package_win64\\build\\usr\\share\\julia\\stdlib\\v1.7\\Pkg\\src\\Pkg.jl:595\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "\n",
    "function addPackage(pkg::String)\n",
    "    if !haskey(Pkg.installed(), pkg)\n",
    "        Pkg.add(pkg)\n",
    "    end\n",
    "end\n",
    "\n",
    "addPackage(\"Distributions\")\n",
    "addPackage(\"LinearAlgebra\")\n",
    "addPackage(\"JuMP\")\n",
    "addPackage(\"Ipopt\")\n",
    "\n",
    "using Distributions, LinearAlgebra, JuMP, Ipopt, Random\n",
    "\n",
    "\n",
    "# Appendices\n",
    "# G.5 Convenience Functions\n",
    "struct SetCategorical{S}\n",
    "    elements::Vector{S} # Set elements (could be repeated)\n",
    "    distr::Categorical # Categorical distribution over set elements\n",
    "\n",
    "    function SetCategorical(elements::AbstractVector{S}) where {S}\n",
    "        weights = ones(length(elements))\n",
    "        return new{S}(elements, Categorical(normalize(weights, 1)))\n",
    "    end\n",
    "\n",
    "    function SetCategorical(elements::AbstractVector{S}, weights::AbstractVector{Float64}) where {S}\n",
    "        ℓ₁ = norm(weights, 1)\n",
    "        if ℓ₁ < 1e-6 || isinf(ℓ₁)\n",
    "            return SetCategorical(elements)\n",
    "        end\n",
    "        distr = Categorical(normalize(weights, 1))\n",
    "        return new{S}(elements, distr)\n",
    "    end\n",
    "end\n",
    "\n",
    "Distributions.rand(D::SetCategorical) = D.elements[rand(D.distr)]\n",
    "Distributions.rand(D::SetCategorical, n::Int) = D.elements[rand(D.distr, n)]\n",
    "\n",
    "function Distributions.pdf(D::SetCategorical, x)\n",
    "    sum(e == x ? w : 0.0 for (e, w) in zip(D.elements, D.distr.p))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580af32e",
   "metadata": {},
   "source": [
    "## Define simple game structures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51f6649",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "best_response (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Algorithm 24.1. Data structure for a simple game.\n",
    "struct SimpleGame\n",
    "    γ # discount factor\n",
    "    ℐ # agents\n",
    "    𝒜 # joint action space\n",
    "    R # joint reward function\n",
    "end\n",
    "\n",
    "\n",
    "# Algorithm 24.2\n",
    "struct SimpleGamePolicy\n",
    "    p # dictionary mapping actions to probabilities\n",
    "\n",
    "    function SimpleGamePolicy(p::Base.Generator)\n",
    "        return SimpleGamePolicy(Dict(p))\n",
    "    end\n",
    "\n",
    "    function SimpleGamePolicy(p::Dict)\n",
    "        vs = collect(values(p))\n",
    "        vs ./= sum(vs)\n",
    "        return new(Dict(k => v for (k, v) in zip(keys(p), vs)))\n",
    "    end\n",
    "\n",
    "    SimpleGamePolicy(ai) = new(Dict(ai => 1.0))\n",
    "end\n",
    "\n",
    "(πi::SimpleGamePolicy)(ai) = get(πi.p, ai, 0.0)\n",
    "\n",
    "function (πi::SimpleGamePolicy)()\n",
    "    D = SetCategorical(collect(keys(πi.p)), collect(values(πi.p)))\n",
    "    return rand(D)\n",
    "end\n",
    "\n",
    "joint(X) = vec(collect(Iterators.product(X...)))\n",
    "\n",
    "joint(π, πi, i) = [i == j ? πi : πj for (j, πj) in enumerate(π)] # helper of best_response\n",
    "\n",
    "function utility(𝒫::SimpleGame, π, i)\n",
    "    𝒜, R = 𝒫.𝒜, 𝒫.R\n",
    "    p(a) = prod(πj(aj) for (πj, aj) in zip(π, a))\n",
    "    return sum(R(a)[i] * p(a) for a in joint(𝒜))\n",
    "end\n",
    "\n",
    "\n",
    "# Algorithm 24.3\n",
    "function best_response(𝒫::SimpleGame, π, i)\n",
    "    U(ai) = utility(𝒫, joint(π, SimpleGamePolicy(ai), i), i)\n",
    "    ai = argmax(U, 𝒫.𝒜[i])\n",
    "    return SimpleGamePolicy(ai)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d0d7fb",
   "metadata": {},
   "source": [
    "## Problem properties\n",
    "Register the properties of Traveler's Dilemma problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "419d3665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleGame(1.0, [1, 2], [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11  …  91, 92, 93, 94, 95, 96, 97, 98, 99, 100], [2, 3, 4, 5, 6, 7, 8, 9, 10, 11  …  91, 92, 93, 94, 95, 96, 97, 98, 99, 100]], joint_reward)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const N_AGENTS = 2\n",
    "ACTIONS = vec(collect(2:100))\n",
    "\n",
    "function joint_reward(a::Tuple{Int64,Int64})\n",
    "    ai, aj = a\n",
    "    return ai == aj ? (ai, aj) : (ai < aj ? (ai + 2, ai - 2) : (aj - 2, aj + 2))\n",
    "end\n",
    "\n",
    "travelersDilemma = SimpleGame(\n",
    "    1.0,\n",
    "    vec(collect(1:N_AGENTS)),\n",
    "    [ACTIONS for _ in 1:N_AGENTS],\n",
    "    joint_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0511468a",
   "metadata": {},
   "source": [
    "## Hierarchical Softmax solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a99f5d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 => (3.3216244433691576e-13, 3.3216244433691576e-13)\n",
      "3 => (4.4837240103375595e-13, 4.4837240103375595e-13)\n",
      "4 => (6.052394346085835e-13, 6.052394346085835e-13)\n",
      "5 => (8.169877814970728e-13, 8.169877814970728e-13)\n",
      "6 => (1.102818152532633e-12, 1.102818152532633e-12)\n",
      "7 => (1.4886487963448598e-12, 1.4886487963448598e-12)\n",
      "8 => (2.0094656891222545e-12, 2.0094656891222545e-12)\n",
      "9 => (2.7124949589624926e-12, 2.7124949589624926e-12)\n",
      "10 => (3.661485210822247e-12, 3.661485210822247e-12)\n",
      "11 => (4.9424880605662504e-12, 4.9424880605662504e-12)\n",
      "12 => (6.671661039763351e-12, 6.671661039763351e-12)\n",
      "13 => (9.005800415445694e-12, 9.005800415445694e-12)\n",
      "14 => (1.2156559009620783e-11, 1.2156559009620783e-11)\n",
      "15 => (1.640963824814931e-11, 1.640963824814931e-11)\n",
      "16 => (2.2150694716930613e-11, 2.2150694716930613e-11)\n",
      "17 => (2.990031035489309e-11, 2.990031035489309e-11)\n",
      "18 => (4.0361197276913615e-11, 4.0361197276913615e-11)\n",
      "19 => (5.4481917619626686e-11, 5.4481917619626686e-11)\n",
      "20 => (7.354289633620451e-11, 7.354289633620451e-11)\n",
      "21 => (9.927252632439671e-11, 9.927252632439671e-11)\n",
      "22 => (1.3400389395520984e-10, 1.3400389395520984e-10)\n",
      "23 => (1.8088633640632005e-10, 1.8088633640632005e-10)\n",
      "24 => (2.441710141885254e-10, 2.441710141885254e-10)\n",
      "25 => (3.295963937296571e-10, 3.295963937296571e-10)\n",
      "26 => (4.4490859442447215e-10, 4.4490859442447215e-10)\n",
      "27 => (6.005637836626082e-10, 6.005637836626082e-10)\n",
      "28 => (8.106763109064119e-10, 8.106763109064119e-10)\n",
      "29 => (1.0942985547591276e-9, 1.0942985547591276e-9)\n",
      "30 => (1.477148535679184e-9, 1.477148535679184e-9)\n",
      "31 => (1.993941948994479e-9, 1.993941948994479e-9)\n",
      "32 => (2.691540079797707e-9, 2.691540079797707e-9)\n",
      "33 => (3.633199042848985e-9, 3.633199042848985e-9)\n",
      "34 => (4.904305655127519e-9, 4.904305655127519e-9)\n",
      "35 => (6.620120051443142e-9, 6.620120051443142e-9)\n",
      "36 => (8.936227117810141e-9, 8.936227117810141e-9)\n",
      "37 => (1.206264444263305e-8, 1.206264444263305e-8)\n",
      "38 => (1.628286604392043e-8, 1.628286604392043e-8)\n",
      "39 => (2.1979568684950434e-8, 2.1979568684950434e-8)\n",
      "40 => (2.966931172124292e-8, 2.966931172124292e-8)\n",
      "41 => (4.004937690416575e-8, 4.004937690416575e-8)\n",
      "42 => (5.406099533756978e-8, 5.406099533756978e-8)\n",
      "43 => (7.297469464177673e-8, 7.297469464177673e-8)\n",
      "44 => (9.850550502741303e-8, 9.850550502741303e-8)\n",
      "45 => (1.329684702318368e-7, 1.329684702318368e-7)\n",
      "46 => (1.7948856350968824e-7, 1.7948856350968824e-7)\n",
      "47 => (2.4228404127144877e-7, 2.4228404127144877e-7)\n",
      "48 => (3.270489244567833e-7, 3.270489244567833e-7)\n",
      "49 => (4.4146928339558476e-7, 4.4146928339558476e-7)\n",
      "50 => (5.959201294514403e-7, 5.959201294514403e-7)\n",
      "51 => (8.044060838612529e-7, 8.044060838612529e-7)\n",
      "52 => (1.0858310813810293e-6, 1.0858310813810293e-6)\n",
      "53 => (1.4657121698254279e-6, 1.4657121698254279e-6)\n",
      "54 => (1.9784926768208362e-6, 1.9784926768208362e-6)\n",
      "55 => (2.670664256334898e-6, 2.670664256334898e-6)\n",
      "56 => (3.604980478374304e-6, 3.604980478374304e-6)\n",
      "57 => (4.866143246181989e-6, 4.866143246181989e-6)\n",
      "58 => (6.568476226859325e-6, 6.568476226859325e-6)\n",
      "59 => (8.866278474311145e-6, 8.866278474311145e-6)\n",
      "60 => (1.1967792301043752e-5, 1.1967792301043752e-5)\n",
      "61 => (1.6154043264801594e-5, 1.6154043264801594e-5)\n",
      "62 => (2.1804244795396132e-5, 2.1804244795396132e-5)\n",
      "63 => (2.943004228946166e-5, 2.943004228946166e-5)\n",
      "64 => (3.972164949801836e-5, 3.972164949801836e-5)\n",
      "65 => (5.3609965675444185e-5, 5.3609965675444185e-5)\n",
      "66 => (7.235013363870352e-5, 7.235013363870352e-5)\n",
      "67 => (9.763380303697166e-5, 9.763380303697166e-5)\n",
      "68 => (0.00013173971320644482, 0.00013173971320644482)\n",
      "69 => (0.0001777352295207307, 0.0001777352295207307)\n",
      "70 => (0.00023974527092388074, 0.00023974527092388074)\n",
      "71 => (0.0003233097190475134, 0.0003233097190475134)\n",
      "72 => (0.00043585583390345347, 0.00043585583390345347)\n",
      "73 => (0.0005873180680054271, 0.0005873180680054271)\n",
      "74 => (0.0007909430744808794, 0.0007909430744808794)\n",
      "75 => (0.0010643207689603159, 0.0010643207689603159)\n",
      "76 => (0.0014306794984720887, 0.0014306794984720887)\n",
      "77 => (0.0019204685506363742, 0.0019204685506363742)\n",
      "78 => (0.0025732144747445296, 0.0025732144747445296)\n",
      "79 => (0.0034395642236743056, 0.0034395642236743056)\n",
      "80 => (0.004583298401682761, 0.004583298401682761)\n",
      "81 => (0.006082890640970693, 0.006082890640970693)\n",
      "82 => (0.008031890842478549, 0.008031890842478549)\n",
      "83 => (0.010537035274913557, 0.010537035274913557)\n",
      "84 => (0.013712611716122647, 0.013712611716122647)\n",
      "85 => (0.017669412870814572, 0.017669412870814572)\n",
      "86 => (0.022496904659211617, 0.022496904659211617)\n",
      "87 => (0.028238409909887522, 0.028238409909887522)\n",
      "88 => (0.03486145482219618, 0.03486145482219618)\n",
      "89 => (0.04222878880462999, 0.04222878880462999)\n",
      "90 => (0.050078975872911255, 0.050078975872911255)\n",
      "91 => (0.05802697019889747, 0.05802697019889747)\n",
      "92 => (0.06559261076171981, 0.06559261076171981)\n",
      "93 => (0.07225764472978617, 0.07225764472978617)\n",
      "94 => (0.07754157806990312, 0.07754157806990312)\n",
      "95 => (0.08107789549775585, 0.08107789549775585)\n",
      "96 => (0.08266990512347333, 0.08266990512347333)\n",
      "97 => (0.08231159472013715, 0.08231159472013715)\n",
      "98 => (0.0801707286095723, 0.0801707286095723)\n",
      "99 => (0.07654321306942709, 0.07654321306942709)\n",
      "100 => (0.07179440907670288, 0.07179440907670288)\n"
     ]
    }
   ],
   "source": [
    "# Algorithm 24.4\n",
    "function softmax_response(𝒫::SimpleGame, π, i, λ)\n",
    "    𝒜i = 𝒫.𝒜[i]\n",
    "    U(ai) = utility(𝒫, joint(π, SimpleGamePolicy(ai), i), i)\n",
    "    return SimpleGamePolicy(ai => exp(λ * U(ai)) for ai in 𝒜i)\n",
    "end\n",
    "\n",
    "\n",
    "# Algorithm 24.9\n",
    "struct HierarchicalSoftmax\n",
    "    λ # precision parameter\n",
    "    k # level\n",
    "    π # initial policy\n",
    "end\n",
    "\n",
    "function HierarchicalSoftmax(𝒫::SimpleGame, λ, k)\n",
    "    π = [SimpleGamePolicy(ai => 1.0 for ai in 𝒜i) for 𝒜i in 𝒫.𝒜]\n",
    "    return HierarchicalSoftmax(λ, k, π)\n",
    "end\n",
    "\n",
    "function solve(M::HierarchicalSoftmax, 𝒫)\n",
    "    π = M.π\n",
    "    for k in 1:M.k\n",
    "        π = [softmax_response(𝒫, π, i, M.λ) for i in 𝒫.ℐ]\n",
    "    end\n",
    "    return π\n",
    "end\n",
    "\n",
    "\n",
    "π = solve(HierarchicalSoftmax(travelersDilemma, 0.3, 4), travelersDilemma)\n",
    "\n",
    "π¹ = π[1].p\n",
    "π² = π[2].p\n",
    "\n",
    "for a in ACTIONS\n",
    "    println(a => (π¹[a], π²[a]))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d0218a",
   "metadata": {},
   "source": [
    "## Reduce the number of actions available\n",
    "Reduce the number of actions available from \\\\$100 to \\\\$20 maximum value can be put down for saving runtime. It is easy to see that this does not greatly affect the conclusion of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aba2429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleGame(1.0, [1, 2], [[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]], joint_reward)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTIONS = vec(collect(2:20))\n",
    "\n",
    "travelersDilemma = SimpleGame(\n",
    "    1.0,\n",
    "    vec(collect(1:N_AGENTS)),\n",
    "    [ACTIONS for _ in 1:N_AGENTS],\n",
    "    joint_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57a294",
   "metadata": {},
   "source": [
    "## Correlated Equilibrium solution\n",
    "General of Nash equilibrium concept by relaxing the assumption that the agents act independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a65d117c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.13.4, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:      361\n",
      "Number of nonzeros in inequality constraint Jacobian.:     8632\n",
      "Number of nonzeros in Lagrangian Hessian.............:        0\n",
      "\n",
      "Total number of variables............................:      361\n",
      "                     variables with only lower bounds:      361\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        1\n",
      "Total number of inequality constraints...............:      722\n",
      "        inequality constraints with only lower bounds:      722\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  5.6619943e+01 2.61e+00 2.61e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  5.5958520e+01 2.40e+00 4.83e+00  -1.0 5.12e-01    -  3.19e-01 8.05e-02f  1\n",
      "   2  5.2682938e+01 1.97e+00 8.26e+00  -1.0 6.26e-01    -  3.27e-01 1.81e-01f  1\n",
      "   3  5.0251394e+01 1.75e+00 4.06e+01  -1.0 1.03e+00    -  3.23e-01 1.12e-01f  1\n",
      "   4  4.2611141e+01 1.15e+00 1.46e+01  -1.0 9.99e-01    -  1.83e-01 3.39e-01h  1\n",
      "   5  3.7957119e+01 9.04e-01 3.19e+02  -1.0 9.30e-01    -  1.00e+00 2.17e-01h  1\n",
      "   6  2.4558543e+01 3.80e-01 4.32e+01  -1.0 1.02e+00    -  3.46e-01 5.79e-01h  1\n",
      "   7  1.7856587e+01 1.52e-01 7.59e+01  -1.0 5.70e-01    -  6.52e-01 5.99e-01h  1\n",
      "   8  1.6186583e+01 1.14e-01 2.51e+03  -1.0 3.80e-01    -  9.42e-01 2.54e-01h  1\n",
      "   9  1.3421564e+01 5.67e-02 4.01e+03  -1.0 3.76e-01    -  1.00e+00 5.01e-01h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10  1.1440937e+01 2.96e-02 9.13e+03  -1.0 2.83e-01    -  1.00e+00 4.78e-01h  1\n",
      "  11  1.0049224e+01 1.90e-02 2.13e+04  -1.0 2.75e-01    -  8.62e-01 3.58e-01h  1\n",
      "  12  8.6601708e+00 1.19e-02 4.15e+04  -1.0 3.02e-01    -  9.12e-01 3.74e-01h  1\n",
      "  13  7.1902483e+00 7.32e-03 4.91e+04  -1.0 7.06e-01    -  6.49e-01 3.84e-01h  1\n",
      "  14  5.1379831e+00 2.58e-03 8.54e+03  -1.0 1.10e+00    -  5.85e-01 6.48e-01h  1\n",
      "  15  4.5883317e+00 1.36e-03 2.16e+05  -1.0 9.72e-01    -  1.00e+00 4.74e-01h  1\n",
      "  16  4.2415134e+00 5.51e-04 3.94e+05  -1.0 2.61e-01    -  1.00e+00 5.93e-01h  1\n",
      "  17  4.0923804e+00 2.12e-04 8.62e+05  -1.0 1.66e-01    -  1.00e+00 6.16e-01h  1\n",
      "  18  4.0408040e+00 9.19e-05 2.45e+06  -1.0 4.38e-02    -  1.00e+00 5.66e-01h  1\n",
      "  19  4.0163103e+00 3.62e-05 5.24e+06  -1.0 2.77e-02    -  1.00e+00 6.06e-01h  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  20  4.0071628e+00 1.50e-05 1.31e+07  -1.0 7.56e-03    -  1.00e+00 5.87e-01h  1\n",
      "  21  4.0029941e+00 5.51e-06 2.61e+07  -1.0 4.54e-03    -  1.00e+00 6.32e-01h  1\n",
      "  22  4.0014417e+00 1.90e-06 5.14e+07  -1.0 1.12e-03    -  1.00e+00 6.56e-01h  1\n",
      "  23  4.0007544e+00 3.43e-07 4.93e+07  -1.0 6.04e-04    -  1.00e+00 8.19e-01h  1\n",
      "  24  4.0006094e+00 2.11e-15 1.25e-06  -1.0 3.81e-05    -  1.00e+00 1.00e+00h  1\n",
      "  25  4.0006094e+00 0.00e+00 1.29e+04  -8.6 1.96e-09    -  1.00e+00 1.00e+00h  1\n",
      "  26  4.0007972e+00 3.33e-15 8.96e+03  -8.6 1.19e-04    -  2.79e-01 7.89e-01f  1\n",
      "  27  4.0008710e+00 4.44e-16 4.70e+03  -8.6 9.10e-05    -  4.73e-01 4.20e-01f  1\n",
      "  28  4.0009632e+00 0.00e+00 2.62e+03  -8.6 8.65e-05    -  4.47e-01 5.57e-01f  1\n",
      "  29  4.0010176e+00 2.00e-15 1.18e+03  -8.6 5.36e-05    -  5.51e-01 5.47e-01f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  30  4.0010509e+00 4.44e-16 4.89e+02  -8.6 3.02e-05    -  5.76e-01 6.05e-01f  1\n",
      "  31  4.0010671e+00 2.22e-15 1.86e+02  -8.6 1.22e-05    -  5.68e-01 6.74e-01f  1\n",
      "  32  4.0010730e+00 2.00e-15 2.74e+01  -8.6 2.44e-06    -  9.58e-01 7.13e-01f  1\n",
      "  33  4.0010730e+00 6.66e-16 2.01e+01  -8.6 3.81e-02    -  1.00e+00 2.52e-05f  2\n",
      "  34  4.0010755e+00 2.22e-16 1.09e-11  -8.6 1.56e-05    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 34\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  -4.0010755127989395e+00    4.0010755127989395e+00\n",
      "Dual infeasibility......:   1.0913936421275139e-11    1.0913936421275139e-11\n",
      "Constraint violation....:   2.2204460492503131e-16    2.2204460492503131e-16\n",
      "Complementarity.........:   3.8591930608468139e-09   -3.8591930608468139e-09\n",
      "Overall NLP error.......:   3.8591930608468139e-09    1.0913936421275139e-11\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 38\n",
      "Number of objective gradient evaluations             = 35\n",
      "Number of equality constraint evaluations            = 38\n",
      "Number of inequality constraint evaluations          = 38\n",
      "Number of equality constraint Jacobian evaluations   = 1\n",
      "Number of inequality constraint Jacobian evaluations = 1\n",
      "Number of Lagrangian Hessian evaluations             = 1\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      1.082\n",
      "Total CPU secs in NLP function evaluations           =      0.109\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "2 => (0.9997562396517259, 0.9997562396511264)\n",
      "3 => (5.926065529476108e-5, 5.926065529484795e-5)\n",
      "4 => (4.421665872558114e-5, 4.4216658725531124e-5)\n",
      "5 => (3.373870103422705e-5, 3.37387010342216e-5)\n",
      "6 => (2.58323639090124e-5, 2.5832363908998007e-5)\n",
      "7 => (1.9264026284864764e-5, 1.9264026284784256e-5)\n",
      "8 => (1.5114335523342138e-5, 1.5114335523293287e-5)\n",
      "9 => (1.09505665612623e-5, 1.0950566561235783e-5)\n",
      "10 => (8.933666414230562e-6, 8.933666414223681e-6)\n",
      "11 => (6.1452489570433694e-6, 6.145248957022569e-6)\n",
      "12 => (5.401003722564376e-6, 5.401003722546813e-6)\n",
      "13 => (3.3553548973670997e-6, 3.3553548973424625e-6)\n",
      "14 => (3.4142315444697542e-6, 3.414231544452215e-6)\n",
      "15 => (1.7294227346094743e-6, 1.7294227345860579e-6)\n",
      "16 => (2.3388464484821836e-6, 2.338846448465748e-6)\n",
      "17 => (7.731309014204436e-7, 7.731315016151712e-7)\n",
      "18 => (1.8036919058484297e-6, 1.8036919058298396e-6)\n",
      "19 => (2.3292916922172793e-7, 2.3292916878685793e-7)\n",
      "20 => (1.6169851779486698e-6, 1.616985177931796e-6)\n"
     ]
    }
   ],
   "source": [
    "# Algorithm 24.6\n",
    "mutable struct JointCorrelatedPolicy\n",
    "    p # dictionary mapping from joint actions to probabilities\n",
    "    JointCorrelatedPolicy(p::Base.Generator) = new(Dict(p))\n",
    "end\n",
    "\n",
    "(π::JointCorrelatedPolicy)(a) = get(π.p, a, 0.0)\n",
    "\n",
    "function (π::JointCorrelatedPolicy)()\n",
    "    D = SetCategorical(collect(keys(π.p)), collect(values(π.p)))\n",
    "    return rand(D)\n",
    "end\n",
    "\n",
    "\n",
    "# Algorithm 24.7 (Utilitarian) [Fixed bug by me]\n",
    "struct CorrelatedEquilibrium end\n",
    "\n",
    "joint(a, ai′, i) = Tuple(k == i ? ai′ : v for (k, v) in enumerate(a))\n",
    "\n",
    "function solve(M::CorrelatedEquilibrium, 𝒫::SimpleGame)\n",
    "    ℐ, 𝒜, R = 𝒫.ℐ, 𝒫.𝒜, 𝒫.R\n",
    "    model = Model(Ipopt.Optimizer)\n",
    "    @variable(model, π[joint(𝒜)] ≥ 0)\n",
    "    @objective(model, Max, sum(sum(π[a] * R(a)[i] for a in joint(𝒜)) for i in ℐ))\n",
    "    @constraint(model, [i = ℐ, ai = 𝒜[i], ai′ = 𝒜[i]],\n",
    "        sum(R(a)[i] * π[a] for a in joint(𝒜) if a[i] == ai)\n",
    "        ≥\n",
    "        sum(R(joint(a, ai′, i))[i] * π[a] for a in joint(𝒜) if a[i] == ai))\n",
    "    @constraint(model, sum(π) == 1)\n",
    "    optimize!(model)\n",
    "    return JointCorrelatedPolicy(a => value(π[a]) for a in joint(𝒜))\n",
    "end\n",
    "\n",
    "\n",
    "π = solve(CorrelatedEquilibrium(), travelersDilemma)\n",
    "\n",
    "π¹ = Dict(a => 0.0 for a in travelersDilemma.𝒜[1])\n",
    "π² = Dict(a => 0.0 for a in travelersDilemma.𝒜[2])\n",
    "\n",
    "for (k, v) in π.p\n",
    "    π¹[k[1]] += v\n",
    "    π²[k[2]] += v\n",
    "end\n",
    "\n",
    "for a in ACTIONS\n",
    "    println(a => (π¹[a], π²[a]))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ff90e",
   "metadata": {},
   "source": [
    "## Fictitious Play solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bf168bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100 iterations, the (deterministic) policy:\n",
      "π¹ = SimpleGamePolicy(Dict(11 => 1.0))\n",
      "π² = SimpleGamePolicy(Dict(11 => 1.0))\n",
      "\n",
      "After 1000 iterations, the (deterministic) policy:\n",
      "π¹ = SimpleGamePolicy(Dict(8 => 1.0))\n",
      "π² = SimpleGamePolicy(Dict(8 => 1.0))\n",
      "\n",
      "After 10000 iterations, the (deterministic) policy:\n",
      "π¹ = SimpleGamePolicy(Dict(5 => 1.0))\n",
      "π² = SimpleGamePolicy(Dict(5 => 1.0))\n",
      "\n",
      "After 100000 iterations, the (deterministic) policy:\n",
      "π¹ = SimpleGamePolicy(Dict(2 => 1.0))\n",
      "π² = SimpleGamePolicy(Dict(2 => 1.0))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Algorithm 24.11\n",
    "mutable struct FictitiousPlay\n",
    "    𝒫 # simple game\n",
    "    i # agent index\n",
    "    N # array of action count dictionaries\n",
    "    πi # current policy\n",
    "end\n",
    "\n",
    "function FictitiousPlay(𝒫::SimpleGame, i)\n",
    "    N = [Dict(aj => 1 for aj in 𝒫.𝒜[j]) for j in 𝒫.ℐ]\n",
    "    πi = SimpleGamePolicy(ai => 1.0 for ai in 𝒫.𝒜[i])\n",
    "    return FictitiousPlay(𝒫, i, N, πi)\n",
    "end\n",
    "\n",
    "(πi::FictitiousPlay)() = πi.πi()\n",
    "\n",
    "(πi::FictitiousPlay)(ai) = πi.πi(ai)\n",
    "\n",
    "function update!(πi::FictitiousPlay, a)\n",
    "    N, 𝒫, ℐ, i = πi.N, πi.𝒫, πi.𝒫.ℐ, πi.i\n",
    "    for (j, aj) in enumerate(a)\n",
    "        N[j][aj] += 1\n",
    "    end\n",
    "    p(j) = SimpleGamePolicy(aj => u / sum(values(N[j])) for (aj, u) in N[j])\n",
    "    π = [p(j) for j in ℐ]\n",
    "    πi.πi = best_response(𝒫, π, i)\n",
    "end\n",
    "\n",
    "\n",
    "# Algorithm 24.10\n",
    "function simulate(𝒫::SimpleGame, π, k_max)\n",
    "    for k = 1:k_max\n",
    "        a = [πi() for πi in π]\n",
    "        for πi in π\n",
    "            update!(πi, a)\n",
    "        end\n",
    "    end\n",
    "    return π\n",
    "end\n",
    "\n",
    "\n",
    "for k_max in [100, 1000, 10000, 100000]\n",
    "    π = simulate(\n",
    "        travelersDilemma,\n",
    "        [FictitiousPlay(travelersDilemma, i) for i in travelersDilemma.ℐ],\n",
    "        k_max)\n",
    "\n",
    "    println(\"After \", k_max, \" iterations, the (deterministic) policy:\")\n",
    "    \n",
    "    π¹ = π[1].πi\n",
    "    π² = π[2].πi\n",
    "    \n",
    "    println(\"π¹ = \", π¹)\n",
    "    println(\"π² = \", π²)\n",
    "    println()\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.1",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
