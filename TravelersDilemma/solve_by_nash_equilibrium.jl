import Pkg
if !haskey(Pkg.installed(), "Ipopt")
    Pkg.add("Ipopt")
end
if !haskey(Pkg.installed(), "JuMP")
    Pkg.add("JuMP")
end

using JuMP, Ipopt

# Algorithm 24.1. Data structure for a simple game.
struct SimpleGame
    Î³ # discount factor
    â„ # agents
    ğ’œ # joint action space
    R # joint reward function
end


# Algorithm 24.2
struct SimpleGamePolicy
    p # dictionary mapping actions to probabilities

    function SimpleGamePolicy(p::Base.Generator)
        return SimpleGamePolicy(Dict(p))
    end

    function SimpleGamePolicy(p::Dict)
        vs = collect(values(p))
        vs ./= sum(vs)
        return new(Dict(k => v for (k, v) in zip(keys(p), vs)))
    end

    SimpleGamePolicy(ai) = new(Dict(ai => 1.0))
end

(Ï€i::SimpleGamePolicy)(ai) = get(Ï€i.p, ai, 0.0)

function (Ï€i::SimpleGamePolicy)()
    D = SetCategorical(collect(keys(Ï€i.p)), collect(values(Ï€i.p)))
    return rand(D)
end

joint(X) = vec(collect(Iterators.product(X...)))

joint(Ï€, Ï€i, i) = [i == j ? Ï€i : Ï€j for (j, Ï€j) in enumerate(Ï€)]

function utility(ğ’«::SimpleGame, Ï€, i)
    ğ’œ, R = ğ’«.ğ’œ, ğ’«.R
    p(a) = prod(Ï€j(aj) for (Ï€j, aj) in zip(Ï€, a))
    return sum(R(a)[i] * p(a) for a in joint(ğ’œ))
end


# Algorithm 24.5. This nonlinear program computes a Nash equilibrium for a simple game ğ’«.
struct NashEquilibrium end

function tensorform(ğ’«::SimpleGame)
    â„, ğ’œ, R = ğ’«.â„, ğ’«.ğ’œ, ğ’«.R
    â„â€² = eachindex(â„)
    ğ’œâ€² = [eachindex(ğ’œ[i]) for i in â„]
    Râ€² = [R(a) for a in joint(ğ’œ)]
    return â„â€², ğ’œâ€², Râ€²
end

function solve(M::NashEquilibrium, ğ’«::SimpleGame)
    â„, ğ’œ, R = tensorform(ğ’«)
    model = Model(Ipopt.Optimizer)
    @variable(model, U[â„])
    @variable(model, Ï€[i = â„, ğ’œ[i]] â‰¥ 0)
    @NLobjective(model, Min,
        sum(U[i] - sum(prod(Ï€[j, a[j]] for j in â„) * R[y][i]
                       for (y, a) in enumerate(joint(ğ’œ))) for i in â„))
    @NLconstraint(model, [i = â„, ai = ğ’œ[i]],
        U[i] â‰¥ sum(
            prod(j == i ? (a[j] == ai ? 1.0 : 0.0) : Ï€[j, a[j]] for j in â„)
            *
            R[y][i] for (y, a) in enumerate(joint(ğ’œ))))
    @constraint(model, [i = â„], sum(Ï€[i, ai] for ai in ğ’œ[i]) == 1)
    optimize!(model)
    Ï€iâ€²(i) = SimpleGamePolicy(ğ’«.ğ’œ[i][ai] => value(Ï€[i, ai]) for ai in ğ’œ[i])
    return [Ï€iâ€²(i) for i in â„]
end


# Properties
const N_AGENTS = 2
const ACTIONS = vec(collect(2:10))

function joint_reward(a::Tuple{Int64, Int64})
    ai, aj = a
    if ai == aj
        return (ai, ai)
    elseif ai < aj
        return (ai + 2, ai - 2)
    end
    return (aj - 2, aj + 2)
end

travelersDilemma = SimpleGame(
    1.0,
    vec(collect(1:N_AGENTS)),
    [ACTIONS for _ in 1:N_AGENTS],
    joint_reward)
    

Ï€ = solve(NashEquilibrium(), travelersDilemma)