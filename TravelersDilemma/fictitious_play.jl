include("properties.jl")


# Algorithm 24.11 (Algorithms for Decision Making)
# MÃ´ hÃ¬nh Fictitious Play
mutable struct FictitiousPlay
    ğ’« # simple game
    i # agent index
    N # array of action count dictionaries
    Ï€i # current policy
end

# Constructor cá»§a mÃ´ hÃ¬nh
function FictitiousPlay(ğ’«::SimpleGame, i)
    N = [Dict(aj => 1 for aj in ğ’«.ğ’œ[j]) for j in ğ’«.â„]
    Ï€i = SimpleGamePolicy(ai => 1.0 for ai in ğ’«.ğ’œ[i])
    return FictitiousPlay(ğ’«, i, N, Ï€i)
end

# Tráº£ vá» action ngáº«u nhiÃªn tá»« policy Ï€i
(Ï€i::FictitiousPlay)() = Ï€i.Ï€i()

# Tráº£ vá» xÃ¡c suáº¥t cá»§a action ai
(Ï€i::FictitiousPlay)(ai) = Ï€i.Ï€i(ai)

# Cáº­p nháº­t mÃ´ hÃ¬nh Fictitious Play
function update!(Ï€i::FictitiousPlay, a)
    N, ğ’«, â„, i = Ï€i.N, Ï€i.ğ’«, Ï€i.ğ’«.â„, Ï€i.i
    # TÄƒng sá»‘ láº§n cÃ¡c action xuáº¥t hiá»‡n
    for (j, aj) in enumerate(a)
        N[j][aj] += 1
    end
    # Cáº­p nháº­t policy má»›i
    p(j) = SimpleGamePolicy(aj => u / sum(values(N[j])) for (aj, u) in N[j])
    Ï€ = [p(j) for j in â„]
    Ï€i.Ï€i = best_response(ğ’«, Ï€, i)
end


# Algorithm 24.10 (Algorithms for Decision Making)
# Láº·p Ä‘á»ƒ cáº­p nháº­t mÃ´ hÃ¬nh
function simulate(ğ’«::SimpleGame, Ï€, k_max)
    for k = 1:k_max
        a = [Ï€i() for Ï€i in Ï€]
        for Ï€i in Ï€
            update!(Ï€i, a)
        end
    end
    return Ï€
end

# Thá»­ nghiá»‡m cÃ¡c tham sá»‘ k_max vÃ  ghi káº¿t quáº£
for k_max in [100, 1000, 10000, 100000]
    Ï€ = simulate(
        travelersDilemma,
        [FictitiousPlay(travelersDilemma, i) for i in travelersDilemma.â„],
        k_max)

    println("After ", k_max, " iterations, the (deterministic) policy:")
    
    Ï€Â¹ = Ï€[1].Ï€i
    Ï€Â² = Ï€[2].Ï€i
    
    println("Ï€Â¹ = ", Ï€Â¹)
    println("Ï€Â² = ", Ï€Â²)
    println()
end