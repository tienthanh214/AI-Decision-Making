include("resource.jl")


# Algorithm 24.1 (Algorithms for Decision Making)
struct SimpleGame
    Î³ # discount factor
    â„ # agents
    ğ’œ # joint action space
    R # joint reward function
end


# Algorithm 24.2 (Algorithms for Decision Making)
struct SimpleGamePolicy
    p # dictionary mapping actions to probabilities

    # Tráº£ vá» policy ngáº«u nhiÃªn
    function SimpleGamePolicy(p::Base.Generator)
        return SimpleGamePolicy(Dict(p))
    end

    # Tráº£ vá» policy tá»« dict
    function SimpleGamePolicy(p::Dict)
        vs = collect(values(p))
        vs ./= sum(vs)
        return new(Dict(k => v for (k, v) in zip(keys(p), vs)))
    end

    SimpleGamePolicy(ai) = new(Dict(ai => 1.0))
end

# Tráº£ vá» policy cá»§a ai
(Ï€i::SimpleGamePolicy)(ai) = get(Ï€i.p, ai, 0.0)

# Tráº£ vá» hÃ nh Ä‘á»™ng ngáº«u nhiÃªn trong policy Ï€i
function (Ï€i::SimpleGamePolicy)()
    D = SetCategorical(collect(keys(Ï€i.p)), collect(values(Ï€i.p)))
    return rand(D)
end

# Tráº£ vá» tÃ­ch cÃ¡c vector
joint(X) = vec(collect(Iterators.product(X...)))

joint(Ï€, Ï€i, i) = [i == j ? Ï€i : Ï€j for (j, Ï€j) in enumerate(Ï€)] # helper of best_response

# HÃ m lá»£i Ã­ch ká»³ vá»ng tá»« ğ’« vÃ  policy Ï€ cá»§a agent i
function utility(ğ’«::SimpleGame, Ï€, i)
    ğ’œ, R = ğ’«.ğ’œ, ğ’«.R
    p(a) = prod(Ï€j(aj) for (Ï€j, aj) in zip(Ï€, a))
    return sum(R(a)[i] * p(a) for a in joint(ğ’œ))
end


# Algorithm 24.3 (Algorithms for Decision Making)
# Tráº£ vá» deterministic policy tá»‘t nháº¥t
function best_response(ğ’«::SimpleGame, Ï€, i)
    U(ai) = utility(ğ’«, joint(Ï€, SimpleGamePolicy(ai), i), i)
    ai = argmax(U, ğ’«.ğ’œ[i])
    return SimpleGamePolicy(ai)
end
